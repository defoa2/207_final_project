{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all = np.load('207_data/saved_data/x_train_3500_balanced.npy')\n",
    "y_train_all = np.load('207_data/saved_data/y_train_3500_balanced.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting 10% of the training data off for validation\n",
    "# no code to save numpy files to drive\n",
    "# use np.save if you want to save it as a file on your local to use if the kernel is restarted\n",
    "random.seed(10)\n",
    "rows_id = random.sample(range(0, 3500), 350)\n",
    "all_rows = np.arange(0, 3500)\n",
    "\n",
    "train_rows_id = np.delete(all_rows, rows_id)\n",
    "\n",
    "x_train = x_train_all[train_rows_id, :, :]\n",
    "y_train = y_train_all[train_rows_id, :, :]\n",
    "\n",
    "x_val = x_train_all[rows_id, :, :]\n",
    "y_val = y_train_all[rows_id, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train/255, (298116000, 3))\n",
    "y_train = y_train.flatten()\n",
    "\n",
    "x_val = np.reshape(x_val/255, (33124000, 3))\n",
    "y_val = y_val.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 6.439 GB of training data: 22.489 s\n",
      "Binning 0.715 GB of validation data: 1.395 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/50] 1 tree, 31 leaves, max depth = 5, train loss: 484.16212, val loss: 484.38841, in 24.160s\n",
      "[2/50] 1 tree, 31 leaves, max depth = 5, train loss: 405.70486, val loss: 405.89710, in 28.119s\n",
      "[3/50] 1 tree, 31 leaves, max depth = 5, train loss: 342.08962, val loss: 342.25337, in 25.770s\n",
      "[4/50] 1 tree, 31 leaves, max depth = 5, train loss: 290.61183, val loss: 290.75228, in 29.302s\n",
      "[5/50] 1 tree, 31 leaves, max depth = 5, train loss: 248.90568, val loss: 249.02666, in 29.196s\n",
      "[6/50] 1 tree, 31 leaves, max depth = 5, train loss: 215.12177, val loss: 215.22535, in 27.148s\n",
      "[7/50] 1 tree, 31 leaves, max depth = 5, train loss: 187.75003, val loss: 187.83919, in 26.187s\n",
      "[8/50] 1 tree, 31 leaves, max depth = 5, train loss: 165.57795, val loss: 165.65346, in 27.625s\n",
      "[9/50] 1 tree, 31 leaves, max depth = 5, train loss: 147.60462, val loss: 147.66960, in 26.809s\n",
      "[10/50] 1 tree, 31 leaves, max depth = 5, train loss: 133.03385, val loss: 133.08860, in 28.858s\n",
      "[11/50] 1 tree, 31 leaves, max depth = 5, train loss: 121.23605, val loss: 121.28282, in 25.317s\n",
      "[12/50] 1 tree, 31 leaves, max depth = 5, train loss: 111.66784, val loss: 111.70702, in 25.873s\n",
      "[13/50] 1 tree, 31 leaves, max depth = 5, train loss: 103.81266, val loss: 103.84652, in 27.444s\n",
      "[14/50] 1 tree, 31 leaves, max depth = 5, train loss: 97.44755, val loss: 97.47696, in 24.100s\n",
      "[15/50] 1 tree, 31 leaves, max depth = 5, train loss: 92.35383, val loss: 92.37877, in 24.473s\n",
      "[16/50] 1 tree, 31 leaves, max depth = 5, train loss: 88.22271, val loss: 88.24393, in 24.832s\n",
      "[17/50] 1 tree, 31 leaves, max depth = 5, train loss: 84.82622, val loss: 84.84429, in 26.703s\n",
      "[18/50] 1 tree, 31 leaves, max depth = 5, train loss: 82.08882, val loss: 82.10366, in 24.377s\n",
      "[19/50] 1 tree, 31 leaves, max depth = 5, train loss: 79.88061, val loss: 79.89289, in 22.665s\n",
      "[20/50] 1 tree, 31 leaves, max depth = 5, train loss: 78.09536, val loss: 78.10474, in 25.804s\n",
      "[21/50] 1 tree, 31 leaves, max depth = 5, train loss: 76.65095, val loss: 76.65802, in 24.953s\n",
      "[22/50] 1 tree, 31 leaves, max depth = 5, train loss: 75.47081, val loss: 75.47606, in 24.805s\n",
      "[23/50] 1 tree, 31 leaves, max depth = 5, train loss: 74.51260, val loss: 74.51586, in 24.677s\n",
      "[24/50] 1 tree, 31 leaves, max depth = 5, train loss: 73.73351, val loss: 73.73533, in 25.086s\n",
      "[25/50] 1 tree, 31 leaves, max depth = 5, train loss: 73.09544, val loss: 73.09602, in 28.385s\n",
      "[26/50] 1 tree, 31 leaves, max depth = 5, train loss: 72.58646, val loss: 72.58559, in 26.594s\n",
      "[27/50] 1 tree, 31 leaves, max depth = 5, train loss: 72.10868, val loss: 72.10761, in 25.043s\n",
      "[28/50] 1 tree, 31 leaves, max depth = 5, train loss: 71.75782, val loss: 71.75598, in 26.200s\n",
      "[29/50] 1 tree, 31 leaves, max depth = 5, train loss: 71.47622, val loss: 71.47358, in 26.545s\n",
      "[30/50] 1 tree, 31 leaves, max depth = 5, train loss: 71.24485, val loss: 71.24142, in 24.017s\n",
      "[31/50] 1 tree, 31 leaves, max depth = 5, train loss: 71.01485, val loss: 71.01141, in 27.276s\n",
      "[32/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.82801, val loss: 70.82446, in 25.692s\n",
      "[33/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.67284, val loss: 70.66913, in 24.016s\n",
      "[34/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.57377, val loss: 70.56982, in 23.664s\n",
      "[35/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.46230, val loss: 70.45841, in 24.059s\n",
      "[36/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.39463, val loss: 70.39040, in 24.729s\n",
      "[37/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.31183, val loss: 70.30771, in 23.764s\n",
      "[38/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.26417, val loss: 70.25973, in 25.427s\n",
      "[39/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.21113, val loss: 70.20617, in 27.965s\n",
      "[40/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.17746, val loss: 70.17232, in 23.968s\n",
      "[41/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.14802, val loss: 70.14243, in 23.397s\n",
      "[42/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.10554, val loss: 70.09991, in 28.671s\n",
      "[43/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.08335, val loss: 70.07745, in 28.543s\n",
      "[44/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.05779, val loss: 70.05176, in 26.531s\n",
      "[45/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.04037, val loss: 70.03421, in 25.317s\n",
      "[46/50] 1 tree, 29 leaves, max depth = 5, train loss: 69.97375, val loss: 69.96768, in 24.040s\n",
      "[47/50] 1 tree, 31 leaves, max depth = 5, train loss: 69.95620, val loss: 69.94986, in 25.357s\n",
      "[48/50] 1 tree, 29 leaves, max depth = 5, train loss: 69.90627, val loss: 69.90009, in 25.564s\n",
      "[49/50] 1 tree, 31 leaves, max depth = 5, train loss: 69.88809, val loss: 69.88152, in 26.498s\n",
      "[50/50] 1 tree, 26 leaves, max depth = 5, train loss: 69.84056, val loss: 69.83374, in 26.273s\n",
      "Fit 50 trees in 1768.847 s, (1541 total leaves)\n",
      "Time spent computing histograms: 77.176s\n",
      "Time spent finding best splits:  0.738s\n",
      "Time spent applying splits:      105.684s\n",
      "Time spent predicting:           54.156s\n",
      "Wall time: 29min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grad_mod = HistGradientBoostingRegressor(learning_rate = 0.1, max_depth = 5,\n",
    "                                         min_samples_leaf = 20, max_iter = 50, verbose = 1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.6797516803246\n",
      "Wall time: 4min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_tr = grad_mod.predict(x_train)\n",
    "print(mean_squared_error(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130.07686096989937\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_val = grad_mod.predict(x_val)\n",
    "print(mean_squared_error(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 6.439 GB of training data: 22.160 s\n",
      "Binning 0.715 GB of validation data: 1.272 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/50] 1 tree, 31 leaves, max depth = 5, train loss: 484.16415, val loss: 484.08505, in 25.782s\n",
      "[2/50] 1 tree, 31 leaves, max depth = 5, train loss: 405.67881, val loss: 405.60213, in 25.393s\n",
      "[3/50] 1 tree, 31 leaves, max depth = 5, train loss: 342.10490, val loss: 342.03054, in 26.679s\n",
      "[4/50] 1 tree, 31 leaves, max depth = 5, train loss: 290.65962, val loss: 290.58719, in 24.297s\n",
      "[5/50] 1 tree, 31 leaves, max depth = 5, train loss: 248.98302, val loss: 248.91271, in 25.557s\n",
      "[6/50] 1 tree, 31 leaves, max depth = 5, train loss: 215.21584, val loss: 215.14775, in 24.845s\n",
      "[7/50] 1 tree, 31 leaves, max depth = 5, train loss: 187.86315, val loss: 187.79715, in 27.172s\n",
      "[8/50] 1 tree, 31 leaves, max depth = 5, train loss: 165.70101, val loss: 165.63687, in 27.004s\n",
      "[9/50] 1 tree, 31 leaves, max depth = 5, train loss: 147.74721, val loss: 147.68492, in 26.136s\n",
      "[10/50] 1 tree, 31 leaves, max depth = 5, train loss: 133.17165, val loss: 133.11126, in 25.163s\n",
      "[11/50] 1 tree, 31 leaves, max depth = 5, train loss: 121.36458, val loss: 121.30596, in 26.998s\n",
      "[12/50] 1 tree, 31 leaves, max depth = 5, train loss: 111.80085, val loss: 111.74395, in 26.364s\n",
      "[13/50] 1 tree, 31 leaves, max depth = 5, train loss: 104.05761, val loss: 104.00189, in 25.849s\n",
      "[14/50] 1 tree, 31 leaves, max depth = 5, train loss: 97.67274, val loss: 97.61763, in 24.261s\n",
      "[15/50] 1 tree, 31 leaves, max depth = 5, train loss: 92.50087, val loss: 92.44602, in 21.497s\n",
      "[16/50] 1 tree, 31 leaves, max depth = 5, train loss: 88.36380, val loss: 88.31038, in 24.246s\n",
      "[17/50] 1 tree, 31 leaves, max depth = 5, train loss: 84.94605, val loss: 84.89269, in 28.332s\n",
      "[18/50] 1 tree, 31 leaves, max depth = 5, train loss: 82.23928, val loss: 82.18744, in 27.439s\n",
      "[19/50] 1 tree, 31 leaves, max depth = 5, train loss: 80.04769, val loss: 79.99713, in 32.694s\n",
      "[20/50] 1 tree, 31 leaves, max depth = 5, train loss: 78.25047, val loss: 78.20081, in 30.850s\n",
      "[21/50] 1 tree, 31 leaves, max depth = 5, train loss: 76.78296, val loss: 76.73401, in 24.002s\n",
      "[22/50] 1 tree, 31 leaves, max depth = 5, train loss: 75.60260, val loss: 75.55419, in 28.314s\n",
      "[23/50] 1 tree, 31 leaves, max depth = 5, train loss: 74.63550, val loss: 74.58759, in 25.224s\n",
      "[24/50] 1 tree, 31 leaves, max depth = 5, train loss: 73.86036, val loss: 73.81269, in 26.739s\n",
      "[25/50] 1 tree, 31 leaves, max depth = 5, train loss: 73.22147, val loss: 73.17412, in 23.987s\n",
      "[26/50] 1 tree, 31 leaves, max depth = 5, train loss: 72.71119, val loss: 72.66436, in 27.893s\n",
      "[27/50] 1 tree, 31 leaves, max depth = 5, train loss: 72.28353, val loss: 72.23697, in 29.084s\n",
      "[28/50] 1 tree, 31 leaves, max depth = 5, train loss: 71.93688, val loss: 71.89076, in 30.179s\n",
      "[29/50] 1 tree, 31 leaves, max depth = 5, train loss: 71.65434, val loss: 71.60843, in 35.553s\n",
      "[30/50] 1 tree, 31 leaves, max depth = 5, train loss: 71.42921, val loss: 71.38367, in 26.268s\n",
      "[31/50] 1 tree, 31 leaves, max depth = 5, train loss: 71.24249, val loss: 71.19715, in 29.268s\n",
      "[32/50] 1 tree, 31 leaves, max depth = 5, train loss: 71.09279, val loss: 71.04777, in 28.646s\n",
      "[33/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.95930, val loss: 70.91428, in 36.710s\n",
      "[34/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.85357, val loss: 70.80862, in 32.235s\n",
      "[35/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.76331, val loss: 70.71845, in 27.301s\n",
      "[36/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.62515, val loss: 70.57954, in 26.289s\n",
      "[37/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.51162, val loss: 70.46541, in 26.876s\n",
      "[38/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.41225, val loss: 70.36561, in 29.353s\n",
      "[39/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.36881, val loss: 70.32246, in 26.534s\n",
      "[40/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.30212, val loss: 70.25529, in 26.429s\n",
      "[41/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.23712, val loss: 70.18982, in 25.197s\n",
      "[42/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.18751, val loss: 70.14002, in 24.815s\n",
      "[43/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.16046, val loss: 70.11314, in 25.433s\n",
      "[44/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.14050, val loss: 70.09326, in 25.283s\n",
      "[45/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.12064, val loss: 70.07356, in 25.521s\n",
      "[46/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.10346, val loss: 70.05641, in 26.155s\n",
      "[47/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.09375, val loss: 70.04681, in 23.898s\n",
      "[48/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.08315, val loss: 70.03616, in 25.348s\n",
      "[49/50] 1 tree, 29 leaves, max depth = 5, train loss: 70.01546, val loss: 69.96751, in 23.082s\n",
      "[50/50] 1 tree, 31 leaves, max depth = 5, train loss: 70.00777, val loss: 69.95980, in 28.046s\n",
      "Fit 50 trees in 1817.277 s, (1548 total leaves)\n",
      "Time spent computing histograms: 76.885s\n",
      "Time spent finding best splits:  0.888s\n",
      "Time spent applying splits:      112.066s\n",
      "Time spent predicting:           54.320s\n",
      "Wall time: 30min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grad_mod = HistGradientBoostingRegressor(learning_rate = 0.1, max_depth = 5,\n",
    "                                         min_samples_leaf = 10, max_iter = 50, verbose = 1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.00594041761113\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = grad_mod.predict(x_train)\n",
    "print(mean_squared_error(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130.4247378586144\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = grad_mod.predict(x_val)\n",
    "print(mean_squared_error(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 6.439 GB of training data: 24.046 s\n",
      "Binning 0.715 GB of validation data: 1.222 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/50] 1 tree, 31 leaves, max depth = 9, train loss: 483.93627, val loss: 483.68486, in 27.059s\n",
      "[2/50] 1 tree, 31 leaves, max depth = 9, train loss: 405.25131, val loss: 405.03809, in 24.227s\n",
      "[3/50] 1 tree, 31 leaves, max depth = 9, train loss: 341.51474, val loss: 341.33319, in 26.461s\n",
      "[4/50] 1 tree, 31 leaves, max depth = 8, train loss: 289.88627, val loss: 289.73078, in 28.262s\n",
      "[5/50] 1 tree, 31 leaves, max depth = 9, train loss: 248.06479, val loss: 247.93128, in 26.952s\n",
      "[6/50] 1 tree, 31 leaves, max depth = 7, train loss: 214.18555, val loss: 214.07013, in 28.845s\n",
      "[7/50] 1 tree, 31 leaves, max depth = 7, train loss: 186.74436, val loss: 186.64414, in 26.908s\n",
      "[8/50] 1 tree, 31 leaves, max depth = 9, train loss: 164.50992, val loss: 164.42275, in 28.040s\n",
      "[9/50] 1 tree, 31 leaves, max depth = 8, train loss: 146.49897, val loss: 146.42262, in 29.593s\n",
      "[10/50] 1 tree, 31 leaves, max depth = 8, train loss: 131.90873, val loss: 131.84155, in 26.194s\n",
      "[11/50] 1 tree, 31 leaves, max depth = 9, train loss: 120.08962, val loss: 120.03009, in 29.451s\n",
      "[12/50] 1 tree, 31 leaves, max depth = 9, train loss: 110.51289, val loss: 110.45970, in 37.121s\n",
      "[13/50] 1 tree, 31 leaves, max depth = 10, train loss: 102.75266, val loss: 102.70507, in 25.425s\n",
      "[14/50] 1 tree, 31 leaves, max depth = 10, train loss: 96.46419, val loss: 96.42129, in 25.973s\n",
      "[15/50] 1 tree, 31 leaves, max depth = 8, train loss: 91.36932, val loss: 91.33042, in 27.653s\n",
      "[16/50] 1 tree, 31 leaves, max depth = 8, train loss: 87.24147, val loss: 87.20597, in 26.324s\n",
      "[17/50] 1 tree, 31 leaves, max depth = 9, train loss: 83.89721, val loss: 83.86451, in 24.975s\n",
      "[18/50] 1 tree, 31 leaves, max depth = 9, train loss: 81.18618, val loss: 81.15593, in 27.320s\n",
      "[19/50] 1 tree, 31 leaves, max depth = 8, train loss: 78.98993, val loss: 78.96168, in 27.185s\n",
      "[20/50] 1 tree, 31 leaves, max depth = 10, train loss: 77.21030, val loss: 77.18394, in 24.857s\n",
      "[21/50] 1 tree, 31 leaves, max depth = 10, train loss: 75.76519, val loss: 75.74049, in 24.401s\n",
      "[22/50] 1 tree, 31 leaves, max depth = 10, train loss: 74.59491, val loss: 74.57175, in 30.173s\n",
      "[23/50] 1 tree, 31 leaves, max depth = 10, train loss: 73.64629, val loss: 73.62428, in 30.517s\n",
      "[24/50] 1 tree, 31 leaves, max depth = 10, train loss: 72.87815, val loss: 72.85721, in 26.661s\n",
      "[25/50] 1 tree, 31 leaves, max depth = 10, train loss: 72.25410, val loss: 72.23419, in 25.744s\n",
      "[26/50] 1 tree, 31 leaves, max depth = 10, train loss: 71.74981, val loss: 71.73046, in 23.750s\n",
      "[27/50] 1 tree, 31 leaves, max depth = 9, train loss: 71.34175, val loss: 71.32267, in 24.983s\n",
      "[28/50] 1 tree, 31 leaves, max depth = 9, train loss: 71.00430, val loss: 70.98598, in 28.049s\n",
      "[29/50] 1 tree, 31 leaves, max depth = 10, train loss: 70.73183, val loss: 70.71411, in 26.668s\n",
      "[30/50] 1 tree, 31 leaves, max depth = 10, train loss: 70.51162, val loss: 70.49425, in 24.027s\n",
      "[31/50] 1 tree, 31 leaves, max depth = 10, train loss: 70.32887, val loss: 70.31201, in 24.642s\n",
      "[32/50] 1 tree, 31 leaves, max depth = 9, train loss: 70.18087, val loss: 70.16447, in 25.818s\n",
      "[33/50] 1 tree, 31 leaves, max depth = 10, train loss: 70.06061, val loss: 70.04465, in 27.647s\n",
      "[34/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.96372, val loss: 69.94797, in 28.019s\n",
      "[35/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.88386, val loss: 69.86849, in 27.534s\n",
      "[36/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.81879, val loss: 69.80366, in 27.917s\n",
      "[37/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.76528, val loss: 69.75045, in 23.802s\n",
      "[38/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.71929, val loss: 69.70460, in 25.544s\n",
      "[39/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.68318, val loss: 69.66867, in 24.658s\n",
      "[40/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.65380, val loss: 69.63929, in 29.196s\n",
      "[41/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.62993, val loss: 69.61557, in 26.097s\n",
      "[42/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.60942, val loss: 69.59533, in 22.412s\n",
      "[43/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.59183, val loss: 69.57772, in 24.019s\n",
      "[44/50] 1 tree, 31 leaves, max depth = 8, train loss: 69.57562, val loss: 69.56187, in 26.594s\n",
      "[45/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.56256, val loss: 69.54898, in 29.487s\n",
      "[46/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.55018, val loss: 69.53700, in 24.778s\n",
      "[47/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.54225, val loss: 69.52917, in 27.641s\n",
      "[48/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.53438, val loss: 69.52164, in 30.418s\n",
      "[49/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.52606, val loss: 69.51326, in 25.714s\n",
      "[50/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.52140, val loss: 69.50871, in 25.894s\n",
      "Fit 50 trees in 1870.173 s, (1550 total leaves)\n",
      "Time spent computing histograms: 96.096s\n",
      "Time spent finding best splits:  0.581s\n",
      "Time spent applying splits:      107.404s\n",
      "Time spent predicting:           52.148s\n",
      "Wall time: 31min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grad_mod = HistGradientBoostingRegressor(learning_rate = 0.1, max_depth = 10,\n",
    "                                         min_samples_leaf = 20, max_iter = 50, verbose = 1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.04026656227765\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = grad_mod.predict(x_train)\n",
    "print(mean_squared_error(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129.42426876189353\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = grad_mod.predict(x_val)\n",
    "print(mean_squared_error(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 6.439 GB of training data: 23.469 s\n",
      "Binning 0.715 GB of validation data: 1.261 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/50] 1 tree, 31 leaves, max depth = 9, train loss: 483.89737, val loss: 484.04706, in 26.959s\n",
      "[2/50] 1 tree, 31 leaves, max depth = 9, train loss: 405.21788, val loss: 405.34408, in 25.584s\n",
      "[3/50] 1 tree, 31 leaves, max depth = 9, train loss: 341.48631, val loss: 341.59464, in 29.546s\n",
      "[4/50] 1 tree, 31 leaves, max depth = 8, train loss: 289.86319, val loss: 289.95762, in 32.062s\n",
      "[5/50] 1 tree, 31 leaves, max depth = 9, train loss: 248.04565, val loss: 248.12941, in 32.773s\n",
      "[6/50] 1 tree, 31 leaves, max depth = 7, train loss: 214.16967, val loss: 214.24547, in 29.896s\n",
      "[7/50] 1 tree, 31 leaves, max depth = 9, train loss: 186.72833, val loss: 186.79772, in 28.930s\n",
      "[8/50] 1 tree, 31 leaves, max depth = 9, train loss: 164.50065, val loss: 164.56560, in 23.829s\n",
      "[9/50] 1 tree, 31 leaves, max depth = 8, train loss: 146.49042, val loss: 146.55182, in 28.495s\n",
      "[10/50] 1 tree, 31 leaves, max depth = 8, train loss: 131.90147, val loss: 131.96047, in 29.375s\n",
      "[11/50] 1 tree, 31 leaves, max depth = 8, train loss: 120.08320, val loss: 120.14073, in 28.614s\n",
      "[12/50] 1 tree, 31 leaves, max depth = 9, train loss: 110.50644, val loss: 110.56312, in 31.231s\n",
      "[13/50] 1 tree, 31 leaves, max depth = 8, train loss: 102.74808, val loss: 102.80448, in 26.071s\n",
      "[14/50] 1 tree, 31 leaves, max depth = 7, train loss: 96.46252, val loss: 96.51861, in 25.861s\n",
      "[15/50] 1 tree, 31 leaves, max depth = 9, train loss: 91.36771, val loss: 91.42372, in 31.331s\n",
      "[16/50] 1 tree, 31 leaves, max depth = 8, train loss: 87.24083, val loss: 87.29697, in 29.499s\n",
      "[17/50] 1 tree, 31 leaves, max depth = 9, train loss: 83.89801, val loss: 83.95468, in 32.074s\n",
      "[18/50] 1 tree, 31 leaves, max depth = 8, train loss: 81.18767, val loss: 81.24486, in 29.908s\n",
      "[19/50] 1 tree, 31 leaves, max depth = 9, train loss: 78.99046, val loss: 79.04795, in 29.301s\n",
      "[20/50] 1 tree, 31 leaves, max depth = 9, train loss: 77.20847, val loss: 77.26637, in 26.769s\n",
      "[21/50] 1 tree, 31 leaves, max depth = 9, train loss: 75.76609, val loss: 75.82435, in 26.302s\n",
      "[22/50] 1 tree, 31 leaves, max depth = 11, train loss: 74.59507, val loss: 74.65385, in 28.962s\n",
      "[23/50] 1 tree, 31 leaves, max depth = 9, train loss: 73.64525, val loss: 73.70437, in 28.291s\n",
      "[24/50] 1 tree, 31 leaves, max depth = 9, train loss: 72.87478, val loss: 72.93447, in 25.018s\n",
      "[25/50] 1 tree, 31 leaves, max depth = 10, train loss: 72.25059, val loss: 72.31070, in 26.012s\n",
      "[26/50] 1 tree, 31 leaves, max depth = 11, train loss: 71.74518, val loss: 71.80573, in 26.361s\n",
      "[27/50] 1 tree, 31 leaves, max depth = 8, train loss: 71.33507, val loss: 71.39591, in 26.149s\n",
      "[28/50] 1 tree, 31 leaves, max depth = 12, train loss: 70.99923, val loss: 71.06035, in 24.845s\n",
      "[29/50] 1 tree, 31 leaves, max depth = 9, train loss: 70.72896, val loss: 70.79058, in 30.723s\n",
      "[30/50] 1 tree, 31 leaves, max depth = 9, train loss: 70.50863, val loss: 70.57062, in 29.312s\n",
      "[31/50] 1 tree, 31 leaves, max depth = 9, train loss: 70.32966, val loss: 70.39207, in 29.399s\n",
      "[32/50] 1 tree, 31 leaves, max depth = 13, train loss: 70.18087, val loss: 70.24339, in 32.026s\n",
      "[33/50] 1 tree, 31 leaves, max depth = 11, train loss: 70.06202, val loss: 70.12481, in 28.180s\n",
      "[34/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.96471, val loss: 70.02767, in 27.091s\n",
      "[35/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.88551, val loss: 69.94861, in 32.817s\n",
      "[36/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.81896, val loss: 69.88250, in 28.283s\n",
      "[37/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.76407, val loss: 69.82770, in 29.031s\n",
      "[38/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.72103, val loss: 69.78481, in 28.039s\n",
      "[39/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.68493, val loss: 69.74924, in 26.157s\n",
      "[40/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.65470, val loss: 69.71916, in 32.741s\n",
      "[41/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.62878, val loss: 69.69318, in 26.960s\n",
      "[42/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.60685, val loss: 69.67122, in 27.313s\n",
      "[43/50] 1 tree, 31 leaves, max depth = 15, train loss: 69.58927, val loss: 69.65407, in 31.928s\n",
      "[44/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.57600, val loss: 69.64090, in 26.494s\n",
      "[45/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.56425, val loss: 69.62926, in 25.849s\n",
      "[46/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.55495, val loss: 69.62006, in 25.669s\n",
      "[47/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.54640, val loss: 69.61160, in 26.461s\n",
      "[48/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.54032, val loss: 69.60561, in 25.042s\n",
      "[49/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.53486, val loss: 69.60033, in 29.137s\n",
      "[50/50] 1 tree, 31 leaves, max depth = 8, train loss: 69.53063, val loss: 69.59622, in 27.571s\n",
      "Fit 50 trees in 1876.727 s, (1550 total leaves)\n",
      "Time spent computing histograms: 100.767s\n",
      "Time spent finding best splits:  0.195s\n",
      "Time spent applying splits:      106.367s\n",
      "Time spent predicting:           51.672s\n",
      "Wall time: 31min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grad_mod = HistGradientBoostingRegressor(learning_rate = 0.1, max_depth = 50,\n",
    "                                         min_samples_leaf = 20, max_iter = 50, verbose = 1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.0743819402174\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = grad_mod.predict(x_train)\n",
    "print(mean_squared_error(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129.46124748794847\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = grad_mod.predict(x_val)\n",
    "print(mean_squared_error(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 6.439 GB of training data: 23.600 s\n",
      "Binning 0.715 GB of validation data: 1.446 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/50] 1 tree, 31 leaves, max depth = 8, train loss: 69.76803, val loss: 69.75657, in 26.506s\n",
      "[2/50] 1 tree, 31 leaves, max depth = 8, train loss: 69.67574, val loss: 69.66455, in 24.075s\n",
      "[3/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.59507, val loss: 69.58168, in 24.500s\n",
      "[4/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.52705, val loss: 69.51270, in 22.006s\n",
      "[5/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.51035, val loss: 69.49698, in 24.734s\n",
      "[6/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.47201, val loss: 69.46070, in 24.289s\n",
      "[7/50] 1 tree, 31 leaves, max depth = 13, train loss: 69.45941, val loss: 69.44869, in 23.549s\n",
      "[8/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.45307, val loss: 69.44219, in 21.736s\n",
      "[9/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.43369, val loss: 69.42280, in 21.884s\n",
      "[10/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.38655, val loss: 69.37238, in 21.342s\n",
      "[11/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.38262, val loss: 69.36863, in 23.896s\n",
      "[12/50] 1 tree, 31 leaves, max depth = 13, train loss: 69.37183, val loss: 69.35893, in 26.409s\n",
      "[13/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.36082, val loss: 69.34990, in 24.105s\n",
      "[14/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.35685, val loss: 69.34599, in 22.792s\n",
      "[15/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.35236, val loss: 69.34206, in 28.231s\n",
      "[16/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.34464, val loss: 69.33457, in 24.289s\n",
      "[17/50] 1 tree, 31 leaves, max depth = 13, train loss: 69.32568, val loss: 69.31502, in 22.555s\n",
      "[18/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.32074, val loss: 69.31038, in 22.514s\n",
      "[19/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.31948, val loss: 69.30898, in 24.997s\n",
      "[20/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.31810, val loss: 69.30750, in 25.855s\n",
      "[21/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.31591, val loss: 69.30584, in 26.612s\n",
      "[22/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.31473, val loss: 69.30455, in 21.338s\n",
      "[23/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.30681, val loss: 69.29706, in 18.078s\n",
      "[24/50] 1 tree, 31 leaves, max depth = 16, train loss: 69.29900, val loss: 69.28917, in 24.605s\n",
      "[25/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.29629, val loss: 69.28655, in 23.446s\n",
      "[26/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.29247, val loss: 69.28281, in 23.394s\n",
      "[27/50] 1 tree, 31 leaves, max depth = 13, train loss: 69.29211, val loss: 69.28256, in 22.522s\n",
      "[28/50] 1 tree, 31 leaves, max depth = 15, train loss: 69.28872, val loss: 69.27922, in 23.623s\n",
      "[29/50] 1 tree, 31 leaves, max depth = 13, train loss: 69.27523, val loss: 69.26609, in 27.205s\n",
      "[30/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.27255, val loss: 69.26336, in 24.119s\n",
      "[31/50] 1 tree, 31 leaves, max depth = 13, train loss: 69.26803, val loss: 69.25910, in 23.630s\n",
      "[32/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.26669, val loss: 69.25748, in 21.940s\n",
      "[33/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.26465, val loss: 69.25552, in 25.758s\n",
      "[34/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.26198, val loss: 69.25266, in 21.202s\n",
      "[35/50] 1 tree, 31 leaves, max depth = 15, train loss: 69.25691, val loss: 69.24706, in 25.052s\n",
      "[36/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.25588, val loss: 69.24605, in 22.238s\n",
      "[37/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.25453, val loss: 69.24487, in 23.647s\n",
      "[38/50] 1 tree, 31 leaves, max depth = 15, train loss: 69.25142, val loss: 69.24064, in 21.499s\n",
      "[39/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.24897, val loss: 69.23870, in 23.911s\n",
      "[40/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.22891, val loss: 69.21792, in 23.882s\n",
      "[41/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.22603, val loss: 69.21534, in 24.763s\n",
      "[42/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.22519, val loss: 69.21445, in 23.514s\n",
      "[43/50] 1 tree, 31 leaves, max depth = 16, train loss: 69.22396, val loss: 69.21345, in 23.232s\n",
      "[44/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.22289, val loss: 69.21220, in 23.241s\n",
      "[45/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.22220, val loss: 69.21158, in 20.448s\n",
      "[46/50] 1 tree, 31 leaves, max depth = 15, train loss: 69.21769, val loss: 69.20703, in 22.186s\n",
      "[47/50] 1 tree, 31 leaves, max depth = 18, train loss: 69.21224, val loss: 69.20177, in 23.549s\n",
      "[48/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.21144, val loss: 69.20083, in 23.445s\n",
      "[49/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.21057, val loss: 69.20022, in 25.016s\n",
      "[50/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.20855, val loss: 69.19792, in 23.209s\n",
      "Fit 50 trees in 1702.310 s, (1550 total leaves)\n",
      "Time spent computing histograms: 36.229s\n",
      "Time spent finding best splits:  0.955s\n",
      "Time spent applying splits:      59.423s\n",
      "Time spent predicting:           28.806s\n",
      "Wall time: 28min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grad_mod = HistGradientBoostingRegressor(learning_rate = 1, max_depth = 50,\n",
    "                                         min_samples_leaf = 20, max_iter = 50, verbose = 1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138.41497489587073\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = grad_mod.predict(x_train)\n",
    "print(mean_squared_error(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.7407676523449\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = grad_mod.predict(x_val)\n",
    "print(mean_squared_error(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 6.439 GB of training data: 33.140 s\n",
      "Binning 0.715 GB of validation data: 3.003 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/50] 1 tree, 31 leaves, max depth = 9, train loss: 570.89601, val loss: 570.68907, in 48.734s\n",
      "[2/50] 1 tree, 31 leaves, max depth = 9, train loss: 560.92443, val loss: 560.71989, in 38.960s\n",
      "[3/50] 1 tree, 31 leaves, max depth = 9, train loss: 551.15122, val loss: 550.94899, in 41.090s\n",
      "[4/50] 1 tree, 31 leaves, max depth = 9, train loss: 541.57253, val loss: 541.37257, in 33.168s\n",
      "[5/50] 1 tree, 31 leaves, max depth = 9, train loss: 532.18439, val loss: 531.98662, in 40.959s\n",
      "[6/50] 1 tree, 31 leaves, max depth = 9, train loss: 522.98308, val loss: 522.78744, in 39.222s\n",
      "[7/50] 1 tree, 31 leaves, max depth = 9, train loss: 513.96493, val loss: 513.77136, in 46.895s\n",
      "[8/50] 1 tree, 31 leaves, max depth = 9, train loss: 505.12617, val loss: 504.93462, in 35.261s\n",
      "[9/50] 1 tree, 31 leaves, max depth = 9, train loss: 496.46327, val loss: 496.27366, in 42.092s\n",
      "[10/50] 1 tree, 31 leaves, max depth = 9, train loss: 487.97254, val loss: 487.78482, in 33.694s\n",
      "[11/50] 1 tree, 31 leaves, max depth = 9, train loss: 479.65065, val loss: 479.46476, in 30.019s\n",
      "[12/50] 1 tree, 31 leaves, max depth = 9, train loss: 471.49437, val loss: 471.31026, in 36.962s\n",
      "[13/50] 1 tree, 31 leaves, max depth = 9, train loss: 463.50050, val loss: 463.31811, in 42.185s\n",
      "[14/50] 1 tree, 31 leaves, max depth = 9, train loss: 455.66557, val loss: 455.48486, in 35.795s\n",
      "[15/50] 1 tree, 31 leaves, max depth = 9, train loss: 447.98656, val loss: 447.80747, in 35.648s\n",
      "[16/50] 1 tree, 31 leaves, max depth = 9, train loss: 440.46039, val loss: 440.28287, in 37.555s\n",
      "[17/50] 1 tree, 31 leaves, max depth = 9, train loss: 433.08405, val loss: 432.90806, in 38.577s\n",
      "[18/50] 1 tree, 31 leaves, max depth = 9, train loss: 425.85440, val loss: 425.67988, in 39.261s\n",
      "[19/50] 1 tree, 31 leaves, max depth = 9, train loss: 418.76866, val loss: 418.59557, in 35.902s\n",
      "[20/50] 1 tree, 31 leaves, max depth = 9, train loss: 411.82391, val loss: 411.65221, in 37.009s\n",
      "[21/50] 1 tree, 31 leaves, max depth = 9, train loss: 405.01741, val loss: 404.84708, in 35.014s\n",
      "[22/50] 1 tree, 31 leaves, max depth = 9, train loss: 398.34627, val loss: 398.17724, in 32.804s\n",
      "[23/50] 1 tree, 31 leaves, max depth = 9, train loss: 391.80797, val loss: 391.64018, in 41.590s\n",
      "[24/50] 1 tree, 31 leaves, max depth = 9, train loss: 385.39964, val loss: 385.23306, in 39.853s\n",
      "[25/50] 1 tree, 31 leaves, max depth = 9, train loss: 379.11885, val loss: 378.95346, in 45.388s\n",
      "[26/50] 1 tree, 31 leaves, max depth = 8, train loss: 372.96315, val loss: 372.79889, in 34.805s\n",
      "[27/50] 1 tree, 31 leaves, max depth = 9, train loss: 366.92986, val loss: 366.76671, in 39.874s\n",
      "[28/50] 1 tree, 31 leaves, max depth = 8, train loss: 361.01671, val loss: 360.85462, in 33.009s\n",
      "[29/50] 1 tree, 31 leaves, max depth = 9, train loss: 355.22112, val loss: 355.06006, in 43.589s\n",
      "[30/50] 1 tree, 31 leaves, max depth = 8, train loss: 349.54093, val loss: 349.38085, in 46.714s\n",
      "[31/50] 1 tree, 31 leaves, max depth = 8, train loss: 343.97378, val loss: 343.81467, in 38.692s\n",
      "[32/50] 1 tree, 31 leaves, max depth = 9, train loss: 338.51734, val loss: 338.35914, in 36.206s\n",
      "[33/50] 1 tree, 31 leaves, max depth = 9, train loss: 333.16942, val loss: 333.01211, in 38.656s\n",
      "[34/50] 1 tree, 31 leaves, max depth = 8, train loss: 327.92803, val loss: 327.77158, in 39.124s\n",
      "[35/50] 1 tree, 31 leaves, max depth = 9, train loss: 322.79078, val loss: 322.63516, in 34.145s\n",
      "[36/50] 1 tree, 31 leaves, max depth = 8, train loss: 317.75580, val loss: 317.60097, in 36.419s\n",
      "[37/50] 1 tree, 31 leaves, max depth = 9, train loss: 312.82107, val loss: 312.66701, in 37.926s\n",
      "[38/50] 1 tree, 31 leaves, max depth = 8, train loss: 307.98449, val loss: 307.83117, in 35.663s\n",
      "[39/50] 1 tree, 31 leaves, max depth = 8, train loss: 303.24412, val loss: 303.09151, in 37.505s\n",
      "[40/50] 1 tree, 31 leaves, max depth = 9, train loss: 298.59814, val loss: 298.44621, in 40.087s\n",
      "[41/50] 1 tree, 31 leaves, max depth = 8, train loss: 294.04461, val loss: 293.89332, in 40.582s\n",
      "[42/50] 1 tree, 31 leaves, max depth = 9, train loss: 289.58152, val loss: 289.43087, in 34.654s\n",
      "[43/50] 1 tree, 31 leaves, max depth = 8, train loss: 285.20742, val loss: 285.05737, in 35.964s\n",
      "[44/50] 1 tree, 31 leaves, max depth = 9, train loss: 280.92017, val loss: 280.77069, in 34.558s\n",
      "[45/50] 1 tree, 31 leaves, max depth = 9, train loss: 276.71823, val loss: 276.56930, in 35.231s\n",
      "[46/50] 1 tree, 31 leaves, max depth = 8, train loss: 272.59991, val loss: 272.45147, in 39.175s\n",
      "[47/50] 1 tree, 31 leaves, max depth = 8, train loss: 268.56340, val loss: 268.41545, in 32.863s\n",
      "[48/50] 1 tree, 31 leaves, max depth = 8, train loss: 264.60723, val loss: 264.45972, in 41.857s\n",
      "[49/50] 1 tree, 31 leaves, max depth = 9, train loss: 260.72997, val loss: 260.58293, in 37.923s\n",
      "[50/50] 1 tree, 31 leaves, max depth = 7, train loss: 256.92961, val loss: 256.78300, in 37.498s\n",
      "Fit 50 trees in 2445.097 s, (1550 total leaves)\n",
      "Time spent computing histograms: 145.407s\n",
      "Time spent finding best splits:  0.804s\n",
      "Time spent applying splits:      168.212s\n",
      "Time spent predicting:           73.875s\n",
      "Wall time: 40min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grad_mod = HistGradientBoostingRegressor(learning_rate = 0.01, max_depth = 50,\n",
    "                                         min_samples_leaf = 20, max_iter = 50, verbose = 1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513.8298948844979\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = grad_mod.predict(x_train)\n",
    "print(mean_squared_error(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519.2806864323281\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = grad_mod.predict(x_val)\n",
    "print(mean_squared_error(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 6.439 GB of training data: 39.484 s\n",
      "Binning 0.715 GB of validation data: 2.242 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/50] 1 tree, 31 leaves, max depth = 8, train loss: 69.75812, val loss: 69.81020, in 36.516s\n",
      "[2/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.72361, val loss: 69.77439, in 36.056s\n",
      "[3/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.69972, val loss: 69.75025, in 47.902s\n",
      "[4/50] 1 tree, 31 leaves, max depth = 8, train loss: 69.61201, val loss: 69.66474, in 39.018s\n",
      "[5/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.53809, val loss: 69.58965, in 36.183s\n",
      "[6/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.47046, val loss: 69.52303, in 36.773s\n",
      "[7/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.46619, val loss: 69.51903, in 32.888s\n",
      "[8/50] 1 tree, 31 leaves, max depth = 13, train loss: 69.40707, val loss: 69.45914, in 31.192s\n",
      "[9/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.39037, val loss: 69.44190, in 40.442s\n",
      "[10/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.37954, val loss: 69.43024, in 35.513s\n",
      "[11/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.37241, val loss: 69.42250, in 33.193s\n",
      "[12/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.37038, val loss: 69.42061, in 33.555s\n",
      "[13/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.36804, val loss: 69.41826, in 32.052s\n",
      "[14/50] 1 tree, 31 leaves, max depth = 16, train loss: 69.35779, val loss: 69.40809, in 34.027s\n",
      "[15/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.34982, val loss: 69.39945, in 28.182s\n",
      "[16/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.33945, val loss: 69.38937, in 34.533s\n",
      "[17/50] 1 tree, 31 leaves, max depth = 13, train loss: 69.33425, val loss: 69.38395, in 32.723s\n",
      "[18/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.31588, val loss: 69.36862, in 33.523s\n",
      "[19/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.31211, val loss: 69.36480, in 43.749s\n",
      "[20/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.29471, val loss: 69.34791, in 53.032s\n",
      "[21/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.29244, val loss: 69.34569, in 45.389s\n",
      "[22/50] 1 tree, 31 leaves, max depth = 15, train loss: 69.28732, val loss: 69.34053, in 50.854s\n",
      "[23/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.28337, val loss: 69.33658, in 42.445s\n",
      "[24/50] 1 tree, 31 leaves, max depth = 13, train loss: 69.28108, val loss: 69.33475, in 45.026s\n",
      "[25/50] 1 tree, 31 leaves, max depth = 8, train loss: 69.27707, val loss: 69.33123, in 44.009s\n",
      "[26/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.27565, val loss: 69.33018, in 41.734s\n",
      "[27/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.26960, val loss: 69.32473, in 47.993s\n",
      "[28/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.26555, val loss: 69.32110, in 50.543s\n",
      "[29/50] 1 tree, 31 leaves, max depth = 15, train loss: 69.26244, val loss: 69.31797, in 50.598s\n",
      "[30/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.25831, val loss: 69.31399, in 40.723s\n",
      "[31/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.25762, val loss: 69.31329, in 39.382s\n",
      "[32/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.25607, val loss: 69.31185, in 34.693s\n",
      "[33/50] 1 tree, 31 leaves, max depth = 13, train loss: 69.25331, val loss: 69.30897, in 35.914s\n",
      "[34/50] 1 tree, 31 leaves, max depth = 10, train loss: 69.25280, val loss: 69.30846, in 35.123s\n",
      "[35/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.25096, val loss: 69.30683, in 41.571s\n",
      "[36/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.24792, val loss: 69.30330, in 44.830s\n",
      "[37/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.24730, val loss: 69.30276, in 38.802s\n",
      "[38/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.24624, val loss: 69.30178, in 41.774s\n",
      "[39/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.24573, val loss: 69.30121, in 45.280s\n",
      "[40/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.24486, val loss: 69.30050, in 37.086s\n",
      "[41/50] 1 tree, 31 leaves, max depth = 9, train loss: 69.24354, val loss: 69.29916, in 34.166s\n",
      "[42/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.24174, val loss: 69.29765, in 50.716s\n",
      "[43/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.24016, val loss: 69.29541, in 40.932s\n",
      "[44/50] 1 tree, 31 leaves, max depth = 13, train loss: 69.23940, val loss: 69.29497, in 39.671s\n",
      "[45/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.23858, val loss: 69.29434, in 37.074s\n",
      "[46/50] 1 tree, 31 leaves, max depth = 13, train loss: 69.23795, val loss: 69.29384, in 34.650s\n",
      "[47/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.23624, val loss: 69.29191, in 35.911s\n",
      "[48/50] 1 tree, 31 leaves, max depth = 11, train loss: 69.23379, val loss: 69.28963, in 32.527s\n",
      "[49/50] 1 tree, 31 leaves, max depth = 12, train loss: 69.23251, val loss: 69.28847, in 32.318s\n",
      "[50/50] 1 tree, 31 leaves, max depth = 14, train loss: 69.23016, val loss: 69.28674, in 29.009s\n",
      "Fit 50 trees in 2608.398 s, (1550 total leaves)\n",
      "Time spent computing histograms: 61.140s\n",
      "Time spent finding best splits:  0.625s\n",
      "Time spent applying splits:      98.527s\n",
      "Time spent predicting:           47.211s\n",
      "Wall time: 43min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grad_mod = HistGradientBoostingRegressor(learning_rate = 1, max_depth = 100,\n",
    "                                         min_samples_leaf = 20, max_iter = 50, verbose = 1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138.4716357696761\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = grad_mod.predict(x_train)\n",
    "print(mean_squared_error(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.79211891797428\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = grad_mod.predict(x_val)\n",
    "print(mean_squared_error(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 6.439 GB of training data: 29.531 s\n",
      "Binning 0.715 GB of validation data: 1.522 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 8, train loss: 69.81064, val loss: 69.87613, in 30.221s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.72043, val loss: 69.78657, in 42.253s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 14, train loss: 69.63077, val loss: 69.69665, in 25.623s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 14, train loss: 69.57062, val loss: 69.63185, in 25.462s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 8, train loss: 69.55881, val loss: 69.62117, in 24.162s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.53458, val loss: 69.59861, in 23.503s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.52816, val loss: 69.59260, in 23.528s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.51667, val loss: 69.58233, in 23.001s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.50629, val loss: 69.57287, in 25.422s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.48685, val loss: 69.55180, in 23.671s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.46331, val loss: 69.53063, in 26.420s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.45725, val loss: 69.52451, in 23.324s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.44565, val loss: 69.51398, in 27.491s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.44380, val loss: 69.51199, in 21.235s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 14, train loss: 69.42970, val loss: 69.49711, in 23.288s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.42314, val loss: 69.48955, in 23.814s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 69.42138, val loss: 69.48777, in 24.229s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.41663, val loss: 69.48352, in 23.469s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.41285, val loss: 69.47890, in 23.541s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.41124, val loss: 69.47727, in 24.605s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.40599, val loss: 69.47171, in 24.495s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.40498, val loss: 69.47091, in 25.968s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.39926, val loss: 69.46710, in 25.138s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 15, train loss: 69.39571, val loss: 69.46372, in 24.606s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 15, train loss: 69.39193, val loss: 69.46047, in 24.229s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 15, train loss: 69.39044, val loss: 69.45942, in 24.919s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.38854, val loss: 69.45726, in 24.529s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 14, train loss: 69.38679, val loss: 69.45536, in 23.402s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 9, train loss: 69.38374, val loss: 69.45251, in 27.262s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.37156, val loss: 69.44010, in 24.572s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 16, train loss: 69.36627, val loss: 69.43530, in 24.488s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 14, train loss: 69.36355, val loss: 69.43243, in 25.880s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.36211, val loss: 69.43057, in 24.061s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.36109, val loss: 69.42952, in 22.896s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.35701, val loss: 69.42617, in 26.868s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.35563, val loss: 69.42470, in 24.313s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.35448, val loss: 69.42370, in 24.735s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.35347, val loss: 69.42280, in 21.095s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.35123, val loss: 69.42104, in 26.343s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.35059, val loss: 69.42026, in 24.128s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 16, train loss: 69.34901, val loss: 69.41853, in 23.739s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.34362, val loss: 69.41326, in 28.146s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 15, train loss: 69.34303, val loss: 69.41269, in 24.106s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.34093, val loss: 69.41049, in 24.260s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.34068, val loss: 69.41020, in 23.468s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 16, train loss: 69.33857, val loss: 69.40840, in 24.149s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.33156, val loss: 69.40247, in 25.938s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.32980, val loss: 69.40041, in 24.649s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 9, train loss: 69.32678, val loss: 69.39720, in 23.189s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.32581, val loss: 69.39636, in 26.866s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 15, train loss: 69.32195, val loss: 69.39266, in 23.577s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.32001, val loss: 69.39071, in 24.727s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 14, train loss: 69.31925, val loss: 69.39009, in 23.133s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 14, train loss: 69.31650, val loss: 69.38779, in 23.945s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.31431, val loss: 69.38564, in 25.882s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.31374, val loss: 69.38516, in 28.514s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.31163, val loss: 69.38324, in 31.960s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.31053, val loss: 69.38235, in 21.530s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 9, train loss: 69.31012, val loss: 69.38207, in 23.723s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.30891, val loss: 69.38074, in 24.247s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.30781, val loss: 69.37940, in 25.178s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.30709, val loss: 69.37875, in 20.602s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 14, train loss: 69.30568, val loss: 69.37736, in 20.492s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 9, train loss: 69.30530, val loss: 69.37699, in 23.310s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 9, train loss: 69.30473, val loss: 69.37665, in 24.367s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.30442, val loss: 69.37636, in 26.089s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.30134, val loss: 69.37347, in 24.455s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.29883, val loss: 69.37105, in 22.903s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.29830, val loss: 69.37052, in 25.037s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.29551, val loss: 69.36722, in 23.298s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.29366, val loss: 69.36527, in 26.186s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.29253, val loss: 69.36411, in 23.399s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.29058, val loss: 69.36254, in 26.684s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.28905, val loss: 69.36080, in 26.368s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 9, train loss: 69.28885, val loss: 69.36056, in 21.520s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.28712, val loss: 69.35888, in 21.516s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.28458, val loss: 69.35701, in 24.316s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 8, train loss: 69.28354, val loss: 69.35613, in 26.850s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.28269, val loss: 69.35524, in 24.846s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 8, train loss: 69.28250, val loss: 69.35505, in 26.025s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.27901, val loss: 69.35173, in 26.769s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.27711, val loss: 69.35041, in 23.546s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 14, train loss: 69.27630, val loss: 69.34959, in 20.081s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.27477, val loss: 69.34795, in 22.861s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85/100] 1 tree, 31 leaves, max depth = 14, train loss: 69.27357, val loss: 69.34698, in 26.016s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 10, train loss: 69.27163, val loss: 69.34541, in 26.094s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.26971, val loss: 69.34304, in 26.184s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 11, train loss: 69.26895, val loss: 69.34240, in 24.622s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.26607, val loss: 69.33870, in 22.365s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.26557, val loss: 69.33832, in 27.026s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.26518, val loss: 69.33787, in 19.612s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.26510, val loss: 69.33782, in 22.241s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 14, train loss: 69.26394, val loss: 69.33663, in 23.861s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.26242, val loss: 69.33540, in 25.019s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 15, train loss: 69.26095, val loss: 69.33388, in 23.469s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.26051, val loss: 69.33353, in 27.888s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 9, train loss: 69.26036, val loss: 69.33341, in 30.070s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.26015, val loss: 69.33313, in 28.047s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 13, train loss: 69.25876, val loss: 69.33207, in 28.516s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 12, train loss: 69.25840, val loss: 69.33178, in 30.600s\n",
      "Fit 100 trees in 2911.677 s, (3100 total leaves)\n",
      "Time spent computing histograms: 67.827s\n",
      "Time spent finding best splits:  0.850s\n",
      "Time spent applying splits:      106.539s\n",
      "Time spent predicting:           53.769s\n",
      "Wall time: 48min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grad_mod = HistGradientBoostingRegressor(learning_rate = 1, max_depth = 50,\n",
    "                                         min_samples_leaf = 20, max_iter = 100, verbose = 1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138.53148296480762\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = grad_mod.predict(x_train)\n",
    "print(mean_squared_error(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.87358952119382\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = grad_mod.predict(x_val)\n",
    "print(mean_squared_error(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
