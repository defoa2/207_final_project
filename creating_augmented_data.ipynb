{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path\n",
    "path = '' # file path to folder where the images are\n",
    "\n",
    "ex_im_path = os.path.join(path, '2007/Jan/2007_1_1.png') \n",
    "\n",
    "im = Image.open(ex_im_path)\n",
    "pix = np.array(im.getdata())\n",
    "pix2 = np.reshape(pix, (430, 400, 4))\n",
    "\n",
    "# find sea ice concentration values\n",
    "pix4 = pix2[400:430, 40:380]\n",
    "plt.imshow(pix4)\n",
    "plt.show()\n",
    "\n",
    "df_sc_color = pd.DataFrame(data=pix4[15])\n",
    "df_sc_color = df_sc_color.drop_duplicates()\n",
    "df_sc_color = df_sc_color.drop([0])\n",
    "\n",
    "percent_list = np.arange(20, 101, 5)\n",
    "\n",
    "df_sc_color['percent'] = percent_list\n",
    "df_sc_color = df_sc_color.reset_index(drop=True)\n",
    "\n",
    "\n",
    "sic_color_mapping_np = df_sc_color.to_numpy()\n",
    "\n",
    "### create a file named saved_data in the main folder\n",
    "# save a mapping reference dataframe\n",
    "sic_path = os.path.join(path, 'saved_data/sic_mapping.npy')\n",
    "np.save(sic_path, sic_color_mapping_np) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a list of dates\n",
    "def generate_dates(dates_list, num_dates):\n",
    "  \"\"\"\n",
    "  take in number of dates to create\n",
    "  return list of year, month, days\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  dates_data = dates_list\n",
    "\n",
    "  dates_sample = dates_data.sample(n=num_dates, random_state = 0)\n",
    "\n",
    "  return dates_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for producing month numbers\n",
    "months_dict = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "\n",
    "# call images from google folder and create list of input image data\n",
    "def open_images(list_dates, miss_idx_list, missing_images = False):\n",
    "  \"\"\"\n",
    "  take list of generated dates\n",
    "  crop images to clean data\n",
    "  return array of image data\n",
    "\n",
    "  \"\"\"\n",
    "  image_data = []\n",
    "  sic_paths = {}\n",
    "\n",
    "  count = 0\n",
    "\n",
    "  if missing_images == False:\n",
    "    for i in list_dates.index:\n",
    "        year = str(list_dates['Year'][i])\n",
    "        month_num = list_dates['Month'][i]\n",
    "        month = months_dict[month_num]\n",
    "        day = list_dates['Day'][i]\n",
    "        file_name = f\"{year}_{month_num}_{day}.png\"\n",
    "\n",
    "        im = Image.open(os.path.join(path, year, str(month), file_name))\n",
    "        im_dat = np.array(im.convert('RGB').getdata())\n",
    "        im_dat = np.reshape(im_dat, (430, 400, 3))\n",
    "        im_dat = im_dat[2:340, 50:330]\n",
    "        \n",
    "        image_data.append(im_dat)\n",
    "        \n",
    "    image_data = np.reshape(image_data, (len(image_data), 338, 280, 3))   \n",
    "    return image_data\n",
    "    \n",
    "\n",
    "  else:\n",
    "    for i in list_dates.index:\n",
    "        year = str(list_dates['Year'][i])\n",
    "        month_num = list_dates['Month'][i]\n",
    "        month = months_dict[month_num]\n",
    "        day = list_dates['Day'][i]\n",
    "\n",
    "        if count in miss_idx_list:\n",
    "            file_name = f\"{year}_{month_num}_{day}_im_dat.npy\"\n",
    "            im_dat = np.load(os.path.join(path, year, str(month), file_name))\n",
    "            im_dat.astype(int)\n",
    "            \n",
    "            sic_path = os.path.join(path, year, str(month), f\"{year}_{month_num}_{day}_sic.npy\")\n",
    "            sic_paths[count] = sic_path\n",
    "            count += 1\n",
    "        else:\n",
    "            file_name = f\"{year}_{month_num}_{day}.png\"\n",
    "\n",
    "            im = Image.open(os.path.join(path, year, str(month), file_name))\n",
    "            im_dat = np.array(im.convert('RGB').getdata())\n",
    "            im_dat = np.reshape(im_dat, (430, 400, 3))\n",
    "            im_dat = im_dat[2:340, 50:330]\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "        image_data.append(np.reshape(im_dat, (338, 280, 3)))\n",
    "\n",
    "    image_data = np.reshape(image_data, (len(image_data), 338, 280, 3))\n",
    "    return image_data, sic_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of reference colors for sea ice concentration percentage\n",
    "sic_color_mapping = np.load('207_data/saved_data/sic_mapping.npy')\n",
    "\n",
    "sic_color_mapping = np.concatenate((sic_color_mapping[:, :3], sic_color_mapping[:, -1:]), axis=1)\n",
    "\n",
    "sic_color_df = pd.DataFrame(sic_color_mapping, columns = [\"Red\", \"Green\", \"Blue\", \"Percent\"])\n",
    "\n",
    "# create a reference list from data frame records\n",
    "list_mst = sic_color_df[['Red', 'Green', 'Blue']].values.tolist()\n",
    "\n",
    "# sea ice concentration image array\n",
    "def sic_output(x_data, sic_paths, miss_idx_list, missing_images = False):\n",
    "    \"\"\"\n",
    "    take list of image data with 3 channels\n",
    "    return list of sea ice concentration image arrays\n",
    "\n",
    "    \"\"\"\n",
    "    sic_images_arr = []\n",
    "\n",
    "    count = 0\n",
    "  \n",
    "    if missing_images == False:\n",
    "\n",
    "        for im in x_data:\n",
    "            sc_image = []\n",
    "            \n",
    "            for row in im:\n",
    "                for pixel_to_search in row:\n",
    "                    \n",
    "                    df_idx = np.where(list(pixel_to_search.tolist() == plist for plist in list_mst))[0]\n",
    "                    if df_idx.size == 0:\n",
    "                        percent = 0\n",
    "                    else:\n",
    "                        percent = sic_color_df['Percent'].iloc[df_idx].values[0]\n",
    "                    sc_image.append(percent)\n",
    "\n",
    "            sc_image = np.reshape(sc_image, (338, 280))\n",
    "            \n",
    "            sic_images_arr.append(sc_image)\n",
    "\n",
    "        sic_images_arr = np.reshape(sic_images_arr, (len(sic_images_arr), 338, 280))\n",
    "    else:\n",
    "        for im in x_data:\n",
    "            sc_image = []\n",
    "            \n",
    "            if count in miss_idx_list:\n",
    "                sc_image = np.load(sic_paths[count])\n",
    "                count += 1\n",
    "\n",
    "            else:\n",
    "                for row in im:\n",
    "                    for pixel_to_search in row:\n",
    "\n",
    "                        df_idx = np.where(list(pixel_to_search.tolist() == plist for plist in list_mst))[0]\n",
    "                        if df_idx.size == 0:\n",
    "                            percent = 0\n",
    "                        else:\n",
    "                            percent = sic_color_df['Percent'].iloc[df_idx].values[0]\n",
    "                        sc_image.append(percent)\n",
    "                    count += 1 \n",
    "            \n",
    "            sc_image = np.reshape(sc_image, (338, 280))\n",
    "            sic_images_arr.append(sc_image)\n",
    "            \n",
    "        sic_images_arr = np.reshape(sic_images_arr, (len(sic_images_arr), 338, 280))        \n",
    "\n",
    "    return sic_images_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_im_date_path = '' # path to N_seaice_extent_daily_v3.0.csv\n",
    "                    # my path is '207_data/saved_data/N_seaice_extent_daily_v3.0.csv'\n",
    "                    # csv file in saved_data folder on google drive\n",
    "\n",
    "dates_data = pd.read_csv(list_im_date_path,\n",
    "                         usecols = [0, 1, 2], header = 0, skiprows = 1, names = ['Year', 'Month', 'Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an all dates pandas data frame\n",
    "\n",
    "days_30 = np.arange(1, 31)\n",
    "days_31 = np.arange(1, 32)\n",
    "days_28 = np.arange(1, 29)\n",
    "days_29 = np.arange(1, 30)\n",
    "\n",
    "years = np.arange(1978, 2024)\n",
    "\n",
    "months = np.arange(1, 13)\n",
    "\n",
    "all_dates = pd.DataFrame(columns = [\"Year\", \"Month\", \"Day\"])\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        if month == 4 or month == 6 or month == 9 or month == 11:\n",
    "            year_col = np.repeat(year, 30)\n",
    "            month_col = np.repeat(month, 30)\n",
    "            new_month = pd.DataFrame({'Year':year_col, 'Month':month_col, 'Day':days_30})\n",
    "            all_dates = pd.concat([all_dates, new_month])\n",
    "        elif month == 2:\n",
    "            if (year % 4) == 0:\n",
    "                year_col = np.repeat(year, 29)\n",
    "                month_col = np.repeat(month, 29)\n",
    "                new_month = pd.DataFrame({'Year':year_col, 'Month':month_col, 'Day':days_29})\n",
    "                all_dates = pd.concat([all_dates, new_month])\n",
    "            else:\n",
    "                year_col = np.repeat(year, 28)\n",
    "                month_col = np.repeat(month, 28)\n",
    "                new_month = pd.DataFrame({'Year':year_col, 'Month':month_col, 'Day':days_28})\n",
    "                all_dates = pd.concat([all_dates, new_month])\n",
    "        else:\n",
    "            year_col = np.repeat(year, 31)\n",
    "            month_col = np.repeat(month, 31)\n",
    "            new_month = pd.DataFrame({'Year':year_col, 'Month':month_col, 'Day':days_31})\n",
    "            all_dates = pd.concat([all_dates, new_month])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start index 298 (1978/oct/26) end index -75 (2023/oct/18)\n",
    "\n",
    "all_dates = all_dates[298:-74]\n",
    "all_dates = all_dates.reset_index(drop=True)\n",
    "intersection = pd.merge(dates_data, all_dates)\n",
    "missing_days = pd.concat([all_dates, intersection]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_days['Missing'] = True\n",
    "missing_days['Missing'].iloc[-10:] = False\n",
    "\n",
    "all_dates = all_dates.merge(missing_days, how = 'left', on = ['Year', 'Month', 'Day'])\n",
    "miss_idx_list = [i for i, x in enumerate(all_dates['Missing'] == True) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x and y data for days that are missing\n",
    "\n",
    "for i in missing_days[:-51].index:\n",
    "    \n",
    "    m_year = missing_days['Year'][i]\n",
    "    m_month = missing_days['Month'][i]\n",
    "    m_day = missing_days['Day'][i]\n",
    "    \n",
    "    get_idx = all_dates[(all_dates['Year'] == m_year) & (all_dates['Month']== m_month) & (all_dates['Day']== m_day)].index[0]\n",
    "    previous_day = all_dates.iloc[get_idx - 1].to_frame().T\n",
    "    next_day = all_dates.iloc[get_idx + 1].to_frame().T\n",
    "    input_days = pd.concat([previous_day, next_day])\n",
    "    \n",
    "    x_blend = open_images(input_days)\n",
    "    y_blend = sic_output(x_blend)\n",
    "    \n",
    "    new_x = (x_blend[0] + x_blend[1])/2\n",
    "    new_y = (y_blend[0] + y_blend[1])/2\n",
    "    \n",
    "    month_name = months[m_month]\n",
    "    save_path = f'207_data/{str(m_year)}/{month_name}'\n",
    "    fname_x = f'{str(m_year)}_{str(m_month)}_{str(m_day)}_im_dat.npy'\n",
    "    fname_y = f'{str(m_year)}_{str(m_month)}_{str(m_day)}_sic.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = generate_dates(all_dates.iloc[:-2961], 3500)\n",
    "train_inputs_sorted = train_inputs.sort_values(by =['Year', 'Month', 'Day']).reset_index(drop=True)\n",
    "\n",
    "train_inputs_sorted = train_inputs_sorted.drop(np.arange(842, 851).tolist())\n",
    "train_inputs_sorted = train_inputs_sorted.drop(np.arange(467, 474).tolist())\n",
    "\n",
    "train_add_in = generate_dates(all_dates.iloc[:-2961], 3516)[-16:]\n",
    "train_inputs_f = pd.concat([train_inputs_sorted, train_add_in])\n",
    "train_inputs_f_sorted = train_inputs_f.sort_values(by = ['Year', 'Month', 'Day']).reset_index(drop=True)\n",
    "\n",
    "transform_to_sic_train = pd.DataFrame(columns = ['Year', 'Month', 'Day', 'Missing'])\n",
    "\n",
    "for i in range(len(train_inputs_f_sorted)):\n",
    "    transform_row = all_dates[(all_dates['Year'] == train_inputs_f_sorted['Year'][i] + 4) & \n",
    "                     (all_dates['Month'] == train_inputs_f_sorted['Month'][i]) &\n",
    "                     (all_dates['Day'] == train_inputs_f_sorted['Day'][i])]\n",
    "    transform_to_sic_train = pd.concat([transform_to_sic_train, transform_row])\n",
    "\n",
    "# train_sic_transform = train_inputs_f_sorted[['Month', 'Day']]\n",
    "# train_sic_transform['Year'] = train_inputs_f_sorted['Year'] + 4\n",
    "\n",
    "miss_idx_list_sample_x = [i for i, x in enumerate(train_inputs_f_sorted['Missing'] == True) if x]\n",
    "miss_idx_list_sample_y = [i for i, x in enumerate(transform_to_sic_train['Missing'] == True) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to check if there are any images that the code are missing/inaccessible \n",
    "# if code returns nothing there is no problem\n",
    "\n",
    "for i in train_inputs_f_sorted.index:\n",
    "    year = str(train_inputs_f_sorted['Year'][i])\n",
    "    month_num = train_inputs_f_sorted['Month'][i]\n",
    "    month = months[month_num]\n",
    "    day = train_inputs_f_sorted['Day'][i]\n",
    "    \n",
    "    if train_inputs_f_sorted['Missing'][i] == True:\n",
    "        file_name = f\"{year}_{month_num}_{day}_im_dat.npy\"\n",
    "    else:\n",
    "        file_name = f\"{year}_{month_num}_{day}.png\"\n",
    "\n",
    "    file_path = os.path.join('207_data', year, month, file_name)\n",
    "    \n",
    "    if os.path.exists(file_path) == False:\n",
    "        print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build training dataset\n",
    "x_train, sic_paths = open_images(train_inputs_f_sorted, miss_idx_list_sample_x, missing_images = True)\n",
    "x_train_path = os.path.join(path, 'saved_data/x_train_3500_balanced.npy')\n",
    "np.save(x_train_path, x_train)\n",
    "y_input, sic_paths = open_images(transform_to_sic_train, miss_idx_list_sample_y, missing_images = True)\n",
    "y_train = sic_output(y_input, sic_paths, miss_idx_list_sample_y, missing_images = True)\n",
    "y_train_path = os.path.join(path, 'saved_data/y_train_3500_balanced.npy')\n",
    "np.save(y_train_path, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build testing dataset\n",
    "missing_test = []\n",
    "sic_paths = []\n",
    "test_dates = all_dates.iloc[-2961:]\n",
    "test_dates_im = test_dates[:1500]\n",
    "test_dates_sic = test_dates[1461:]\n",
    "\n",
    "test_im_dat = open_images(test_dates_im, missing_test, missing_images = False)\n",
    "x_test_path = os.path.join(path, 'saved_data/x_test_1500_balanced.npy')\n",
    "np.save(x_test_path, test_im_dat)\n",
    "test_sic_y = sic_output(open_images(test_dates_sic, missing_test, missing_images = False),\n",
    "                        sic_paths, missing_test, missing_images = False)\n",
    "y_test_path = os.path.join(path, 'saved_data/y_test_1500_balanced.npy')\n",
    "np.save(y_test_path, test_sic_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in dataset for future use after saving\n",
    "x_train_path = os.path.join(path, 'saved_data/x_train_3500_balanced.npy')\n",
    "y_train_path = os.path.join(path, 'saved_data/y_train_3500_balanced.npy')\n",
    "x_test_path = os.path.join(path, 'saved_data/x_test_1500_balanced.npy')\n",
    "y_test_path = os.path.join(path, 'saved_data/y_test_1500_balanced.npy')\n",
    "\n",
    "x_train = np.load(x_train_path)\n",
    "y_train = np.load(y_train_path)\n",
    "\n",
    "x_test = np.load(x_test_path)\n",
    "y_test = np.load(y_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('207_data/saved_data/x_train_3500_balanced.npy')\n",
    "y_train = np.load('207_data/saved_data/y_train_3500_balanced.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 338, 280)\n",
      "(3150, 338, 280)\n"
     ]
    }
   ],
   "source": [
    "random.seed(10)\n",
    "rows_id = random.sample(range(0, 3500), 350)\n",
    "all_rows = np.arange(0, 3500)\n",
    "\n",
    "train_rows_id = np.delete(all_rows, rows_id)\n",
    "\n",
    "x_train = x_train[train_rows_id, :, :]\n",
    "y_train = y_train[train_rows_id, :, :]\n",
    "\n",
    "x_val = x_train[rows_id, :, :]\n",
    "y_val = y_train[rows_id, :, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
