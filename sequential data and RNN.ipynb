{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('207_data/saved_data/x_train_sequential.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq = np.zeros(shape = (85176000, 4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_seq = []\n",
    "count = 0\n",
    "pix_pos = 0\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    if count == 0:\n",
    "        im_1 = x_train[i]\n",
    "        count += 1\n",
    "    elif count == 1:\n",
    "        im_2 = x_train[i]\n",
    "        count += 1\n",
    "    elif count == 2:\n",
    "        im_3 = x_train[i]\n",
    "        count += 1\n",
    "    else:\n",
    "        im_4 = x_train[i]\n",
    "        \n",
    "        for i in range(im_4.shape[0]):\n",
    "            for j in range(im_4.shape[1]):\n",
    "                year_pos = 0\n",
    "                x_train_seq[pix_pos][year_pos] = im_1[i][j]\n",
    "                year_pos += 1\n",
    "                x_train_seq[pix_pos][year_pos] = im_2[i][j]\n",
    "                year_pos += 1\n",
    "                x_train_seq[pix_pos][year_pos] = im_3[i][j]\n",
    "                year_pos += 1\n",
    "                x_train_seq[pix_pos][year_pos] = im_4[i][j]\n",
    "                year_pos += 1\n",
    "                pix_pos += 1\n",
    "        count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('207_data/saved_data/x_train_sequential_pixel.npy', x_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq = np.load('207_data/saved_data/x_train_sequential_pixel.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_seq = np.load('207_data/saved_data/y_train_sequential.npy').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 125)               16125     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 630       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 16,761\n",
      "Trainable params: 16,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "    # Input layer\n",
    "model.add(tf.keras.layers.SimpleRNN(\n",
    "        units=125,                      # Number of neurons in the hidden layer\n",
    "        input_shape=(4,3),             # Input dimension\n",
    "        activation='tanh'             # Activation function (e.g., 'relu')\n",
    "    ))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units = 5,\n",
    "    activation = 'relu'\n",
    "))\n",
    "\n",
    "    # Output layer\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=1,                      # Output dimension (1 for regression)\n",
    "    activation='linear'           # Linear activation for regression\n",
    "))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "builtin_function_or_method"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "76659/76659 [==============================] - 725s 9ms/step - loss: 158.0051 - val_loss: 99.9955\n",
      "Epoch 2/5\n",
      "76659/76659 [==============================] - 728s 9ms/step - loss: 149.2104 - val_loss: 96.5842\n",
      "Epoch 3/5\n",
      "76659/76659 [==============================] - 736s 10ms/step - loss: 281.2974 - val_loss: 1313.9163\n",
      "Epoch 4/5\n",
      "76659/76659 [==============================] - 721s 9ms/step - loss: 1165.7985 - val_loss: 1215.7117\n",
      "Epoch 5/5\n",
      "76659/76659 [==============================] - 724s 9ms/step - loss: 1161.9265 - val_loss: 1215.6625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158.005051</td>\n",
       "      <td>99.995506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149.210419</td>\n",
       "      <td>96.584198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>281.297394</td>\n",
       "      <td>1313.916260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1165.798462</td>\n",
       "      <td>1215.711670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1161.926514</td>\n",
       "      <td>1215.662476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     val_loss\n",
       "0   158.005051    99.995506\n",
       "1   149.210419    96.584198\n",
       "2   281.297394  1313.916260\n",
       "3  1165.798462  1215.711670\n",
       "4  1161.926514  1215.662476"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(\n",
    "  x = x_train_seq,\n",
    "  y = y_train_seq,\n",
    "  validation_split=0.1,  # use 10% of the examples as a validation set\n",
    "  batch_size = 1000,\n",
    "  epochs = 5\n",
    ")\n",
    "\n",
    "history = pd.DataFrame(history.history)\n",
    "display(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 150)               23100     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 755       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 23,861\n",
      "Trainable params: 23,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "    # Input layer\n",
    "model.add(tf.keras.layers.SimpleRNN(\n",
    "        units=150,                      # Number of neurons in the hidden layer\n",
    "        input_shape=(4,3),             # Input dimension\n",
    "        activation='tanh'             # Activation function (e.g., 'relu')\n",
    "    ))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units = 5,\n",
    "    activation = 'relu'\n",
    "))\n",
    "\n",
    "    # Output layer\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=1,                      # Output dimension (1 for regression)\n",
    "    activation='linear'           # Linear activation for regression\n",
    "))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "76659/76659 [==============================] - 1044s 13ms/step - loss: 192.0750 - val_loss: 97.2247\n",
      "Epoch 2/3\n",
      "76659/76659 [==============================] - 1001s 13ms/step - loss: 136.6713 - val_loss: 85.8986\n",
      "Epoch 3/3\n",
      "76659/76659 [==============================] - 1016s 13ms/step - loss: 151.8192 - val_loss: 91.0699\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153.893738</td>\n",
       "      <td>97.224724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134.789581</td>\n",
       "      <td>85.898605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159.252365</td>\n",
       "      <td>91.069862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss   val_loss\n",
       "0  153.893738  97.224724\n",
       "1  134.789581  85.898605\n",
       "2  159.252365  91.069862"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(\n",
    "  x = x_train_seq,\n",
    "  y = y_train_seq,\n",
    "  validation_split=0.1,  # use 10% of the examples as a validation set\n",
    "  batch_size = 1000,\n",
    "  epochs = 3\n",
    ")\n",
    "\n",
    "history = pd.DataFrame(history.history)\n",
    "display(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 150)               23100     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 24,621\n",
      "Trainable params: 24,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "    # Input layer\n",
    "model.add(tf.keras.layers.SimpleRNN(\n",
    "        units=150,                      # Number of neurons in the hidden layer\n",
    "        input_shape=(4,3),             # Input dimension\n",
    "        activation='tanh'             # Activation function (e.g., 'relu')\n",
    "    ))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units = 10,\n",
    "    activation = 'relu'\n",
    "))\n",
    "\n",
    "    # Output layer\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=1,                      # Output dimension (1 for regression)\n",
    "    activation='linear'           # Linear activation for regression\n",
    "))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "76659/76659 [==============================] - 841s 11ms/step - loss: 164.6004 - val_loss: 102.8681\n",
      "Epoch 2/2\n",
      "76659/76659 [==============================] - 828s 11ms/step - loss: 167.0428 - val_loss: 91.3580\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164.600449</td>\n",
       "      <td>102.868111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167.042847</td>\n",
       "      <td>91.358025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss    val_loss\n",
       "0  164.600449  102.868111\n",
       "1  167.042847   91.358025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(\n",
    "  x = x_train_seq,\n",
    "  y = y_train_seq,\n",
    "  validation_split=0.1,  # use 10% of the examples as a validation set\n",
    "  batch_size = 1000,\n",
    "  epochs = 2\n",
    ")\n",
    "\n",
    "history = pd.DataFrame(history.history)\n",
    "display(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "76659/76659 [==============================] - 795s 10ms/step - loss: 142.8184 - val_loss: 259.0263\n",
      "Epoch 2/6\n",
      "76659/76659 [==============================] - 826s 11ms/step - loss: 213.5074 - val_loss: 94.9469\n",
      "Epoch 3/6\n",
      "76659/76659 [==============================] - 837s 11ms/step - loss: 226.8304 - val_loss: 152.4938\n",
      "Epoch 4/6\n",
      "76659/76659 [==============================] - 827s 11ms/step - loss: 212.9824 - val_loss: 117.8238\n",
      "Epoch 5/6\n",
      "76659/76659 [==============================] - 825s 11ms/step - loss: 206.2468 - val_loss: 103.5018\n",
      "Epoch 6/6\n",
      "76659/76659 [==============================] - 828s 11ms/step - loss: 292.9288 - val_loss: 400.3237\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142.818436</td>\n",
       "      <td>259.026337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213.507370</td>\n",
       "      <td>94.946915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226.830383</td>\n",
       "      <td>152.493759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212.982422</td>\n",
       "      <td>117.823761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206.246765</td>\n",
       "      <td>103.501823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>292.928833</td>\n",
       "      <td>400.323700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss    val_loss\n",
       "0  142.818436  259.026337\n",
       "1  213.507370   94.946915\n",
       "2  226.830383  152.493759\n",
       "3  212.982422  117.823761\n",
       "4  206.246765  103.501823\n",
       "5  292.928833  400.323700"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 22min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(\n",
    "  x = x_train_seq,\n",
    "  y = y_train_seq,\n",
    "  validation_split=0.1,  # use 10% of the examples as a validation set\n",
    "  batch_size = 1000,\n",
    "  epochs = 6\n",
    ")\n",
    "\n",
    "history = pd.DataFrame(history.history)\n",
    "display(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 150)               23100     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 24,621\n",
      "Trainable params: 24,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "    # Input layer\n",
    "model.add(tf.keras.layers.SimpleRNN(\n",
    "        units=150,                      # Number of neurons in the hidden layer\n",
    "        input_shape=(4,3),             # Input dimension\n",
    "        activation='tanh'             # Activation function (e.g., 'relu')\n",
    "    ))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units = 10,\n",
    "    activation = 'relu'\n",
    "))\n",
    "\n",
    "    # Output layer\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=1,                      # Output dimension (1 for regression)\n",
    "    activation='linear'           # Linear activation for regression\n",
    "))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "76659/76659 [==============================] - 879s 11ms/step - loss: 199.9505 - val_loss: 74.4398\n",
      "Epoch 2/5\n",
      "76659/76659 [==============================] - 864s 11ms/step - loss: 113.3454 - val_loss: 97.2478\n",
      "Epoch 3/5\n",
      "76659/76659 [==============================] - 860s 11ms/step - loss: 113.3204 - val_loss: 81.2318\n",
      "Epoch 4/5\n",
      "76659/76659 [==============================] - 862s 11ms/step - loss: 113.0338 - val_loss: 78.3361\n",
      "Epoch 5/5\n",
      "76659/76659 [==============================] - 870s 11ms/step - loss: 113.4421 - val_loss: 101.1754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.076660</td>\n",
       "      <td>74.439796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113.152107</td>\n",
       "      <td>97.247826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113.492081</td>\n",
       "      <td>81.231850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113.276947</td>\n",
       "      <td>78.336136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113.604164</td>\n",
       "      <td>101.175354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss    val_loss\n",
       "0  130.076660   74.439796\n",
       "1  113.152107   97.247826\n",
       "2  113.492081   81.231850\n",
       "3  113.276947   78.336136\n",
       "4  113.604164  101.175354"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 12min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(\n",
    "  x = x_train_seq,\n",
    "  y = y_train_seq,\n",
    "  validation_split=0.1,  # use 10% of the examples as a validation set\n",
    "  batch_size = 1000,\n",
    "  epochs = 5\n",
    ")\n",
    "\n",
    "history = pd.DataFrame(history.history)\n",
    "display(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 150)               23100     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 24,621\n",
      "Trainable params: 24,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "    # Input layer\n",
    "model.add(tf.keras.layers.SimpleRNN(\n",
    "        units=150,                      # Number of neurons in the hidden layer\n",
    "        input_shape=(4,3),             # Input dimension\n",
    "        activation='tanh'             # Activation function (e.g., 'relu')\n",
    "    ))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units = 10,\n",
    "    activation = 'relu'\n",
    "))\n",
    "\n",
    "    # Output layer\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=1,                      # Output dimension (1 for regression)\n",
    "    activation='linear'           # Linear activation for regression\n",
    "))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "153317/153317 [==============================] - 1064s 7ms/step - loss: 165.6143 - val_loss: 92.5342\n",
      "Epoch 2/5\n",
      "153317/153317 [==============================] - 1036s 7ms/step - loss: 115.4506 - val_loss: 83.5824\n",
      "Epoch 3/5\n",
      "153317/153317 [==============================] - 1045s 7ms/step - loss: 114.9425 - val_loss: 83.8908\n",
      "Epoch 4/5\n",
      "153317/153317 [==============================] - 1035s 7ms/step - loss: 113.6301 - val_loss: 76.0350\n",
      "Epoch 5/5\n",
      "153317/153317 [==============================] - 1373s 9ms/step - loss: 113.3622 - val_loss: 100.8273\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.900177</td>\n",
       "      <td>92.534157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115.730400</td>\n",
       "      <td>83.582397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114.334999</td>\n",
       "      <td>83.890816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114.615089</td>\n",
       "      <td>76.035004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113.500565</td>\n",
       "      <td>100.827347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss    val_loss\n",
       "0  123.900177   92.534157\n",
       "1  115.730400   83.582397\n",
       "2  114.334999   83.890816\n",
       "3  114.615089   76.035004\n",
       "4  113.500565  100.827347"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 32min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(\n",
    "  x = x_train_seq,\n",
    "  y = y_train_seq,\n",
    "  validation_split=0.1,  # use 10% of the examples as a validation set\n",
    "  batch_size = 500,\n",
    "  epochs = 5\n",
    ")\n",
    "\n",
    "history = pd.DataFrame(history.history)\n",
    "display(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "76659/76659 [==============================] - 1191s 15ms/step - loss: 110.9050 - val_loss: 85.5043\n",
      "Epoch 2/4\n",
      "76659/76659 [==============================] - 1052s 14ms/step - loss: 110.7844 - val_loss: 112.8509\n",
      "Epoch 3/4\n",
      "76659/76659 [==============================] - 1054s 14ms/step - loss: 111.0131 - val_loss: 95.8821\n",
      "Epoch 4/4\n",
      "76659/76659 [==============================] - 1048s 14ms/step - loss: 111.8242 - val_loss: 105.5732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.904991</td>\n",
       "      <td>85.504303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.784393</td>\n",
       "      <td>112.850914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111.013107</td>\n",
       "      <td>95.882133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111.824165</td>\n",
       "      <td>105.573181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss    val_loss\n",
       "0  110.904991   85.504303\n",
       "1  110.784393  112.850914\n",
       "2  111.013107   95.882133\n",
       "3  111.824165  105.573181"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 12min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(\n",
    "  x = x_train_seq,\n",
    "  y = y_train_seq,\n",
    "  validation_split=0.1,  # use 10% of the examples as a validation set\n",
    "  batch_size = 1000,\n",
    "  epochs = 4\n",
    ")\n",
    "\n",
    "history = pd.DataFrame(history.history)\n",
    "display(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('207_data/saved_models/simple_rnn_1_epoch_weights')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
